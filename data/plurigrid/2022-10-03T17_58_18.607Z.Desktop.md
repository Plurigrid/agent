# Paper of the Day
# Track of the Day
# üçâ

https://twitter.com/mtg_upf
MTG-UPF
@mtg_upf
Research group of
[@UPFBarcelona](https://twitter.com/UPFBarcelona)
(part of
[@dtic_upf](https://twitter.com/dtic_upf)
). Audio signal processing, music information retrieval, musical interfaces, computational musicology and more

---

https://twitter.com/EP_ScienceTech/status/1565273064895553538

  

[

![](https://pbs.twimg.com/profile_images/1060543459180904449/fFR4Q5aC_x96.jpg)

](https://twitter.com/EP_ScienceTech)

[

STOA Panel



](https://twitter.com/EP_ScienceTech)

[

@EP_ScienceTech

](https://twitter.com/EP_ScienceTech)

"[#AI](https://twitter.com/hashtag/AI?src=hashtag_click)-tools can support the learning process of musicians" ![üëâ](https://abs-0.twimg.com/emoji/v2/svg/1f449.svg "Right pointing backhand index")Interview

[@emiliagogu](https://twitter.com/emiliagogu)

[@EU_ScienceHub](https://twitter.com/EU_ScienceHub)

on [#ArtificialIntelligence](https://twitter.com/hashtag/ArtificialIntelligence?src=hashtag_click) & [#music](https://twitter.com/hashtag/music?src=hashtag_click)![üéµ](https://abs-0.twimg.com/emoji/v2/svg/1f3b5.svg "Musical note")- EU [#research](https://twitter.com/hashtag/research?src=hashtag_click): [https://wp.me/panTdn-36I](https://t.co/2uDPKZNrUM)

[@BennieMols](https://twitter.com/BennieMols)

[#H2020](https://twitter.com/hashtag/H2020?src=hashtag_click) [#HorizonEU](https://twitter.com/hashtag/HorizonEU?src=hashtag_click)

[@Ircam](https://twitter.com/Ircam)

[@DTIC_UPF](https://twitter.com/DTIC_UPF)

[@CSLab_UPF](https://twitter.com/CSLab_UPF)

[@mtg_upf](https://twitter.com/mtg_upf)

[@TrompaMusic](https://twitter.com/TrompaMusic)

[@DigitalJazz1](https://twitter.com/DigitalJazz1)

[#ESMH](https://twitter.com/hashtag/ESMH?src=hashtag_click)

![[../Media/Pasted image 20220930122620.png]]

https://sciencemediahub.eu/2022/08/31/a-scientists-opinion-interview-with-emilia-gomez-on-ai-in-music/

# A scientist‚Äôs opinion: Interview with Emilia G√≥mez on AI in music

on¬†August 31, 2022

**[Emilia G√≥mez](https://emiliagomez.com/about/)**¬†is a senior researcher at the Joint Research Centre of the European Commission in Sevilla and a guest professor of the Department of Information and Communication Technologies at the Universitat Pompeu Fabra in Barcelona.

---

In recent years you worked on two large European projects that investigated AI to analyse music: PHENICX and TROMPA. Both of them are finished. What were they about?

**Emilia G√≥mez**: In PHENICX we created an app that gave the user access to information about Beethoven‚Äôs third symphony, called Eroica, both before, during and after the concert. The idea behind the app was that it would make complex classical music more accessible for audiences that are not so familiar with classical music. The app would help for example to find patterns in the symphony, or find out how a theme is played by different instruments.

TROMPA was a more recent Horizon2020-project in which we built and enriched public-domain musical databases by combining human and artificial intelligence. We enhanced musical scores and brought them into the public domain. We focused on five different communities: choir singers, orchestras, musicologists, piano players and music enthusiasts. For each community we created some web based application where people could benefit from and contribute to repertoire in the public domain.

---

What is the impact that AI is already having on music professionals?

**Emilia G√≥mez**: At the moment AI-tools have the potential to support the learning process of musicians. Piano players or choir singers can record their rehearsals or concerts and let the AI-tool compare them. Music teachers can use AI to analyse the achievements of their students. Musicologists can use these techniques to learn about music in a different way. Composers can use them for inspiration or to locate certain material that they want to use.

AI also has some risks that we need to address. For instance, imagine that an AI system is used to evaluate music students in exams. We then need to make sure this system is, for instance, fair and transparent. This is in line with the EU approach towards trustworthy AI.

---

What are some grand challenges in your field?

**Emilia G√≥mez**: For pieces of music that are complex, such as symphonic music or choir music, the transcription from audio to score is still a big challenge for AI. Another challenge is, when an AI-tool is given a certain song, to find another song that is similar. Basically we still do not have a good definition of what it means that two songs are similar. And then there is the challenge of automatically separating different instruments from any piece of music.

---

Will there come a time that AI captures all the aspects of music in the way humans do?

**Emilia G√≥mez**: I find it important to realise that music is not just ‚Äòany kind of data‚Äô, as some people think. There are many aspects of music that lie beyond the data itself, such as culture and emotion. Music is much more than the acoustic signal and it is much more connected to emotion than language, for example. To integrate culture and emotion in the analysis of music is very hard for a machine.

---

## Alexandre D√©fossez
https://ai.honu.io/

About me
Alexandre D√©fossez, defossez at fb.com.
Research scientist at FAIR Paris.
Formerly CIFRE PhD student at FAIR Paris and Sierra at INRIA Paris, under the supervision of L√©on Bottou (FAIR), Nicolas Usunier (FAIR) and Francis Bach (INRIA).
[scholar] [github] [twitter]
Interests
Convex and non convex optimization, stochastic gradient methods, source separation, audio processing and synthesis. Amateur DJ and composer [artist website].

## Publications

-   Hybrid Spectrogram and Waveform Source Separation.¬†MDX Workshop, ISMIR 2021.¬†[[paper]](https://arxiv.org/abs/2111.03600)¬†[[code]](https://github.com/facebookresearch/demucs)¬†[[samples]](https://soundcloud.com/honualx/sets/source-separation-in-the-waveform-domain)  
    A. D√©fossez.
-   Differentiable Model Compression via Pseudo Quantization Noise.¬†Preprint 2021.¬†[[paper]](https://arxiv.org/abs/2104.09987)¬†[[code]](https://github.com/facebookresearch/diffq)  
    A. D√©fossez*, Y. Adi*, G. Synnaeve.
-   Deep Recurrent Encoder: A scalable end-to-end network to model brain signals.¬†Prerint 2021.¬†[[paper]](https://arxiv.org/abs/2103.02339)¬†[[code]](https://github.com/facebookresearch/deepmeg-recurrent-encoder)  
    O. Chehab, A. D√©fossez, J.C. Loiseau, A. Gramfort, J.R. King.
-   Real Time Speech Enhancement in the Waveform Domain.¬†Interspeech 2020.¬†[[paper]](https://arxiv.org/abs/2006.12847)¬†[[audio samples]](https://facebookresearch.github.io/denoiser/)¬†[[code]](https://github.com/facebookresearch/denoiser)  
    A. D√©fossez, G. Synnaeve, Y. Adi.
-   A Simple Convergence Proof of Adam and Adagrad.¬†Preprint 2020.¬†[[paper]](https://arxiv.org/abs/2003.02395)  
    A. D√©fossez, L. Bottou, F. Bach, N. Usunier.
-   Music Source Separation in the Waveform Domain.¬†Preprint 2019.¬†[[paper]](https://arxiv.org/abs/1911.13254)¬†[[github]](https://github.com/facebookresearch/demucs/tree/v2)¬†[[audio samples]](https://ai.honu.io/papers/demucs/)  
    A. D√©fossez, N. Usunier, L. Bottou, F. Bach.
-   Demucs: Deep Extractor for Music Sources with extra unlabeled data remixed.¬†Preprint 2019.¬†[[paper]](https://arxiv.org/abs/1909.01174)  
    A. D√©fossez, N. Usunier, L. Bottou, F. Bach.
-   Regression versus classification for neural network based audio source localization.¬†WASPAA 2019.¬†[[paper]](https://hal.inria.fr/hal-02125985/)  
    L. Perotin, A. D√©fossez, E. Vincent, R. Serizel, A. Gu√©rin
-   SING: Symbol-to-Instrument Neural Generator.¬†NIPS 2018.¬†[[paper]](https://research.fb.com/publications/sing-symbol-to-instrument-neural-generator/)¬†[[github]](https://github.com/facebookresearch/SING)¬†[[poster]](https://ai.honu.io/misc/poster_sing_nips_2018.pdf)¬†[[audio samples]](https://research.fb.com/wp-content/themes/fb-research/research/sing-paper/)¬†[[slides]](https://ai.honu.io/presentations/sing/sing_inria.html).  
    A. D√©fossez, N. Zeghidour, N. Usunier, L. Bottou, F. Bach.
-   AdaBatch: Efficient Gradient Aggregation Rules for Sequential and Parallel Stochastic Gradient Methods.¬†Preprint 2017.¬†[[paper]](https://arxiv.org/pdf/1711.01761). A. D√©fossez, F. Bach.
-   Constant step size least-mean-square: Bias-variance trade-offs and optimal sampling distributions.¬†AI Stats 2015.¬†[[AI Stats version]](http://proceedings.mlr.press/v38/defossez15.pdf),¬†[[arXiv version]](https://arxiv.org/pdf/1412.0156). A. D√©fossez, F. Bach.

## Software

-   [Demucs](https://github.com/facebookresearch/demucs): Music source separation, winning model from the Sony 2021 MDX challenge. Can separate drums, bass, and vocals from the rest of the accompaniment.¬†[Jaime Altozano loves it!](https://www.youtube.com/watch?v=4_l31Vucrmo&t=347s)
-   [Julius](https://github.com/adefossez/julius): Efficient implementations of classical Digital Signal Processing algorithms in PyTorch, fully differentiable and with CUDA support. Resampling, FFT based convolutions, FIR low pass filters and decomposition of a signal over multiple frequency bands in the waveform domain are implemented.
-   [Denoiser](https://github.com/facebookresearch/denoiser): Real time speech denoising in the waveform domain. Can be used with Zoom or other VC software with a virtual soundcard (e.g. Soundflower on a Mac).¬†[Live demo :)](https://www.youtube.com/watch?v=77cm_MVtLfk)


## Teaching

### 2018

Teaching assistant for the¬†[Deep Learning: Do-It-Yourself!](https://www.di.ens.fr/~lelarge/dldiy/)¬†class at Ecole Normale Superieure:

-   Introduction, 14/09/2018:¬†[slides](https://ai.honu.io/presentations/cours_ens_1.html)
-   Optimization, 26/10/2018:¬†[slides](https://ai.honu.io/presentations/cours_ens_2.html),¬†[notebook](https://ai.honu.io/presentations/notebooks/diy_2018_optim.ipynb)

## Misc.

I wrote my PhD manuscript on the¬†[Optimization of Fast Deep Learning Network for Audio Analysis and Synthesis](https://ai.honu.io/misc/Deep%20learning%20networks%20for%20audio%20analysis%20and%20synthesis.pdf). Half of it is on audio synthesis and source separation, and the other half is on adaptive and stochastic optimization.


## ‚àà
The symbol ‚àà¬†**indicates¬†set membership¬†and means ‚Äúis an element of‚Äù**¬†so that the statement x‚ààA means that x is an element of the set A. In other words, x is one of the objects in the collection of (possibly many) objects in the set A.

![set universal](https://www.mathsisfun.com/images/symbols/set-u.svg) set universal	Universal Set: set of all possible values
(in the area of interest)

Math refresher 

https://twitter.com/germank/status/1571818401349214208

Case: The idea of an ouroboros in what AI can output -- and depleting the set of information  
https://twitter.com/germank/status/1571818401349214208
"Interested in controlling language models and other NLP models to be more faithful, unbiased, and adapted to our needs? We have an **internship** position role to be filled ASAP. [https://europe.naverlabs.com/job/energy-based-models-for-controlled-text-generation-internship-2/‚Ä¶](https://t.co/EPSxJ9jcO7)

[

![Image](https://pbs.twimg.com/media/FdA4UQuXEAA3MkD?format=jpg&name=900x900)

If there was just a better model for why AI systems just work only in the past. https://europe.naverlabs.com/job/energy-based-models-for-controlled-text-generation-internship-2/ 
How to get the data points from external places into the internal places -- the internal mesh cloud seems to always cut it out. Reject it. 


](https://twitter.com/germank/status/1571818401349214208/photo/

![[../Media/Screen Shot 2022-09-30 at 1.05.23 PM.png]]


### REFERENCES

[1] Parshakova et al.,¬†[Global Autoregressive Models for Data-Efficient Sequence Learning](https://arxiv.org/abs/1909.07063), In CoNLL 2019

[2] Khalifa et al.,¬†[A Distributional Approach to Controlled Text Generation](https://arxiv.org/abs/2012.11635), In ICLR-2021

[3] Korbak et al.¬†[Controlling Conditional Language Models with Distributional Policy Gradients](https://arxiv.org/pdf/2112.00791.pdf),¬†In ICML 2022

[4] Korbak et al.,¬†[On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting](https://arxiv.org/abs/2206.00761)¬†(_to appear in_¬†NeurIPS 2022)

[5] Eikema et al.,¬†[Sampling from Energy-Based Models with Quality/Efficiency Trade-offs](https://arxiv.org/abs/2112.05702)¬†(_under review_)

---

Really enjoying these writing and writing enhancement tools. 

https://quillbot.com/

---

# [Home](http://guillaumeslizewicz.com/)

[Notes](http://guillaumeslizewicz.com/posts)¬†[Studio](http://studio.guillaumeslizewicz.com/)

Hello,

I‚Äôm Guillaume Slizewicz, a designer based in Brussels.

I have a¬†[studio](http://studio.guillaumeslizewicz.com/), where I create objects and installations.

I am part of¬†[Algolit](https://www.algolit.net/), a Brussel-based group around algorithmic-literature, free code and texts.

I often collaborate with¬†[Urban Species](https://urbanspecies.org/en/about), a multidisciplinary research group.

I mainly work with technology, design and social sciences. I observe, build, write, take pictures and code.

[Notes](http://guillaumeslizewicz.com/posts/)¬†‚Ä¢¬†[Categories](http://www.guillaumeslizewicz.com/categories/)¬†‚Ä¢¬†[Tags](http://www.guillaumeslizewicz.com/tags/)

[Instagram](https://instagram.com/guillaume_slizewicz)¬†‚Ä¢¬†[twitter](https://twitter.com/Guillaume_Slize)


---

## URBAN SPECIES 
AN ACTION-RESEARCH GROUP BASED IN BRUSSELS FOCUSING ON CITIZEN PARTICIPATION

As part of its prototyping strategies and experiments, Urban Species collaborates with developers, graphic designers, citizens, associations, public authorities and a whole series of species, human or not, living or not, digital or not.

Urban Species brings together researchers from ULB (LoUISe, Faculty of Architecture, Grap, Faculty of Social Sciences and Philosophy) and Luca School of Arts (Intermedia).

https://urbanspecies.org/en/about

![[../Media/Screen Shot 2022-09-30 at 1.09.54 PM.png]]

http://guillaumeslizewicz.com/posts/2021/future_vision/

### Whose Memories?

http://guillaumeslizewicz.com/posts/2020/i_can_remember/

The piece has three main layers of memories: the most obvious is the personal one, highlighted by the location of the shooting and the data that is based on. The second, still visible, is the memories of the algorithms, the labels and words embedded inside them. The third, often unaccounted for is the memory of the people who are part of the dataset, the one that has been extracted to create algorithms.


#### Local

This piece has been made in a rural area. The photograph that constitute the dataset document the landscape and daily life there. These photographs are the one used to create the poems. They are the images, the instants kept of this moment, and with years, memory will start erasing all the rest. Photograph are totems for invoking recessing feelings of past times. They are the memories that remain: partial, biased and framed.

By putting the poems back into the place they were ‚Äúinspired‚Äù by, It might convey a little more of the place and show what translation errors algorithms have made.


![[../Media/Pasted image 20220930131111.png]]

### Poem Generation

In order to create poems from the photos, I used two main external tools: google vision API and Color summarizer by Martin Krzywinski. These two algorithms, when used with the photograph dataset, produced two distinct vocabularies: labels and colour descriptions. These two vocabularies were subsequently merged via tracery, a python tool, to create the poem. The process is described below.

![[../Media/Pasted image 20220930131121.png]]

## How does DARPA Work? 

https://benjaminreinhardt.com/wddw




https://www.figma.com/file/NIcd5iMIrkLdfgVrNtiJJj/Let's-Play!-Kids-Book?node-id=401%3A2
https://thenounproject.com/icon/idea-5210832/
https://thenounproject.com/icon/light-bulb-78393/
https://thenounproject.com/icon/idea-354907/
https://thenounproject.com/icon/light-bulb-79249/
https://thenounproject.com/icon/light-bulb-77814/
https://thenounproject.com/icon/idea-70135/
https://thenounproject.com/icon/idea-146566/
https://thenounproject.com/icon/idea-68980/
https://thenounproject.com/icon/idea-5210858/
https://thenounproject.com/icon/idea-361091/
https://thenounproject.com/icon/idea-5210832/
https://www.google.com/search?q=japanese+company+black+cat+pickup&rlz=1C5CHFA_enUS890US890&sxsrf=ALiCzsYs_Yca8YPIHKyHlOyOp2Lfk6aLnw:1664589047920&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiTope39b36AhXVFlkFHYTHBzkQ_AUoAXoECAIQAw&biw=1008&bih=555&dpr=3#imgrc=gGeH8v5YuwFDzM
https://huggingface.co/spaces/anaxagoras7/gauravgs-text-summarizer
https://quillbot.com/
https://caseorganic.medium.com/why-you-should-be-using-puma-browser-c44f5269d8cf
https://mirror.xyz/0x0966262125B5E01B5D77B862830a341419BC2872/y-aaFWpbogZt5jWGqu6sVlOG-fKh0p-5V6l2o01yyy0
https://rhizomaticsystem.com/index.php/Articles#Stanford_DAO_Workshop_2022
https://benjaminreinhardt.com/wddw#self-link
https://benjaminreinhardt.com/parpa
https://benjaminreinhardt.com/wddw
https://twitter.com/ben_reinhardt
https://www.google.com/search?q=biosemantics&rlz=1C5CHFA_enUS890US890&oq=biosemantics&aqs=chrome..69i57j0i512j0i30l3j0i15i30j0i30j0i15i30l2j0i30.1639j0j7&sourceid=chrome&ie=UTF-8
https://www.google.com/search?q=biosemiotics&rlz=1C5CHFA_enUS890US890&oq=biosemio&aqs=chrome.0.0i512j69i57j0i512l8.1890j0j7&sourceid=chrome&ie=UTF-8
https://www.upress.umn.edu/book-division/books/a-foray-into-the-worlds-of-animals-and-humans
https://www.upress.umn.edu/Plone/book-division/books/prismatic-ecology
https://www.upress.umn.edu/book-division/books/art-and-cosmotechnics
https://liooil.neocities.org/
https://mitpress.mit.edu/9780262045353/active-inference/


## Claude Shannon 

# Claude Shannon, "Father of Information Theory," Celebrated at Bell Labs

![IMG_2676.JPG](https://images.squarespace-cdn.com/content/v1/522e117ee4b0d5218db669a1/1462375623845-NWZ1FQPJLQ0DM9CWROU2/IMG_2676.JPG?format=1000w)

![IMG_2673.JPG](https://images.squarespace-cdn.com/content/v1/522e117ee4b0d5218db669a1/1462375623808-FWL8AOMIE121Y3EN88LQ/IMG_2673.JPG?format=750w)

![IMG_2668.JPG](https://images.squarespace-cdn.com/content/v1/522e117ee4b0d5218db669a1/1462375624177-EBUBV0S5ZOVWRIOQ2BUM/IMG_2668.JPG?format=750w)

![cs1.jpg](https://images.squarespace-cdn.com/content/v1/522e117ee4b0d5218db669a1/1462375926453-PY26QN84NDJNJ4FZ7S42/cs1.jpg?format=1500w)

Two hundred and fifty information theorists, scientists, engineers and researchers from around the world converged at Nokia Bell Labs in Murray Hill last Thursday and Friday to celebrate the centennial of mathematician Claude Shannon (born April 30, 1916, in Petoskey, Michigan.)¬†[Shannon](https://www.bell-labs.com/claude-shannon/)¬†authored a sensational and game-changing 1948 paper,¬†_‚ÄúA Mathematical Theory of Communication,‚Äù_¬†proposing that data from any kind of message‚Äîwhether audio, video, or text‚Äîcould be reduced to ‚Äúbits‚Äù of information (‚Äúbit,‚Äù a contraction of ‚Äúbinary‚Äù and ‚Äúdigital,‚Äú was attributed by Shannon to a colleague, John Tukey.)¬† Shannon suggested that measurable bits of information could be captured ‚Äúdigitally,‚Äù and that data transmissions were governed by laws and principles related to the source, signal, capacity of the transmitter, and ‚Äúnoise‚Äù or interference during transmission.¬†¬† As author Jon Gertner wrote in¬†_The Idea Factory,_¬†"mathematicians would debate not whether Shannon was ahead of his contemporaries..., [but] whether he was twenty, or thirty, or fifty years ahead."¬†

The Nokia Bell Labs conference entitled,¬†"[The Future of the Information Age](https://www.bell-labs.com/claude-shannon/)", opened with a rich sequence of talks by¬†_Irwin Jacobs_¬†(who co-founded Qualcomm in 1985 with no financing, no business plan, and no product),¬†_Robert Metcalfe_¬†(inventor of Ethernet in 1973 and founder of 3Com Corporation,¬†_Eric Schmidt_¬†(Executive Chairman of Alphabet Inc., which encompasses Google Inc.),¬†_Amber Case_¬†(‚Äúcyborg anthropologist‚Äù and user experience designer), and¬†_Henry Markram_¬†(neuroscientist and founder of the Blue Brain Project focused on algorithmic "reconstruction and simulation of the brain on supercomputers").

Afternoon research demonstrations and a technology showcase highlighted topics such as augmented intelligence, robotic animation and collaboration, autonomous vehicles, ‚Äúzero-touch clouds,‚Äù and the future digital fabric integrating ‚Äúsmart‚Äù cities with rural living.¬†

A dazzling half-hour compression of Shannon's work by Vincent Poor, Dean of Princeton University's School of Engineering and Applied Science, and Michelle Effros, Professor of Electrical Engineering at California Institute of Technology on Friday dramatized his impact. ¬†

Using a tag-team approach, the pair recounted in 2-minute segments Shannon's astounding accomplishments in 9 areas of inquiry:¬†

-   ¬†¬†Capacity
-   ¬† Multi-user Channels
-   ¬† Channel Coding
-   ¬† Detection and Hypothesis Testing
-   ¬† Source Coding
-   ¬† Learning and Big Data
-   ¬† Complexity and Combinatorics
-   ¬† Cybersecurity
-   ¬† Applications of information theory beyond the traditional communications realm.

Today, seven decades later, research in all of these areas can be traced directly to Claude Shannon's visionary insights developed amidst the interdisciplinary culture of Bell Labs.¬†¬†

Though aspects of the Conference pointed to a utopian future of humankind made ever-smarter and more effective by total information access and connectivity, anthropologist and tech designer Amber Case's talk on "Designing Calm Technology" offered a refreshingly contrarian view.¬† She sees the oft-cited "50 billion devices online by 2020" as a nightmare scenario, and shudders at the incessant beeps and bleeps in the "Dystopian Kitchen of the Future" designed by techies who "haven't read history" and "have no idea how things really work."

Case regrets our current cacophony of interruptive tools.¬† She argues that well-designed technology will demand just¬†_some_¬†of our attention,¬†_only when necessary_, and that designers should focus on the task and desired results, rather than the gadgets themselves.¬† "You shouldn't be a systems engineer to live in your own home," she claims.

Those of us concerned by the under-branding of humanities should be buoyed by Case's personal thoughts shared backstage after her talk.¬†¬† She was raised without TV (both parents were in broadcasting and wanted a break when at home), with World Book encyclopedia, Plato's dialogues, and Scott Joplin rags close at hand.¬† When leaning toward attending MIT or Caltech, her Math professor implored her to "go to a liberal arts college where they teach you how to think."¬†Case majored in Anthropology at Lewis and Clark College in Portland, Oregon, and is now a ‚Äúuser experience designer‚Äù working to optimize the interaction of humans, computers, creative culture, design, and our societal goals.¬†Explore her ideas at¬†[CaseOrganic.com](http://caseorganic.com/).¬†¬†¬†

For a dive into the legacy of Claude Shannon and Bell Labs, including women tech pioneers and human computers, go to¬†[https://www.bell-labs.com/claude-shannon](https://www.bell-labs.com/claude-shannon/).


# ‚ôæ
